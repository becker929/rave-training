{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8b55f8-2f36-47ba-9422-34c7e6a9cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import gin\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293c087e-66ec-4311-86d7-8ae2ae50ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/RAVE\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16963253-0830-4d1d-9c14-2b9879bb1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rave\n",
    "import rave.core\n",
    "import rave.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5211a7f-aba9-4f82-ad10-62ebb0c5e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, time, gc\n",
    "\n",
    "# Timing utilities\n",
    "start_time = None\n",
    "\n",
    "def start_timer():\n",
    "    global start_time\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_max_memory_allocated()\n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "def end_timer_and_print(local_msg):\n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "    print(\"\\n\" + local_msg)\n",
    "    print(\"Total execution time = {:.3f} sec\".format(end_time - start_time))\n",
    "    print(\"Max memory used by tensors = {} bytes\".format(torch.cuda.max_memory_allocated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24bc8b3-8f96-475d-96f7-e793eedca7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"separate_phases_04\"\n",
    "CONFIG = [\"v2\"]\n",
    "DB_PATH = \"/home/ubuntu/preprocessed/\"\n",
    "MAX_STEPS = 1500\n",
    "VAL_EVERY = 100\n",
    "N_SIGNAL = 131072\n",
    "BATCH = 8\n",
    "ckpt = None\n",
    "OVERRIDE = []\n",
    "WORKERS = 8\n",
    "GPU = None\n",
    "DERIVATIVE = False\n",
    "NORMALIZE = False\n",
    "PROGRESS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d948fd-4853-49ef-a77a-148f0cd4f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gin_extension(config_name: str) -> str:\n",
    "    if config_name[-4:] != '.gin':\n",
    "        config_name += '.gin'\n",
    "    return config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33d37bc-1aa4-4d92-b541-6b86cafc6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    gin.parse_config_files_and_bindings(\n",
    "        map(add_gin_extension, CONFIG),\n",
    "        OVERRIDE,\n",
    "    )\n",
    "    model = rave.RAVE()\n",
    "    if DERIVATIVE:\n",
    "        model.integrator = rave.dataset.get_derivator_integrator(model.sr)[1]\n",
    "\n",
    "    dataset = rave.dataset.get_dataset(\n",
    "        DB_PATH, model.sr, N_SIGNAL, derivative=DERIVATIVE, normalize=NORMALIZE\n",
    "    )\n",
    "    train, val = rave.dataset.split_dataset(dataset, 98)\n",
    "    num_workers = WORKERS\n",
    "\n",
    "    if os.name == \"nt\" or sys.platform == \"darwin\":\n",
    "        num_workers = 0\n",
    "\n",
    "    train = DataLoader(\n",
    "        train, BATCH, True, drop_last=True, num_workers=num_workers\n",
    "    )\n",
    "    val = DataLoader(val, BATCH, False, num_workers=num_workers)\n",
    "\n",
    "    # CHECKPOINT CALLBACKS\n",
    "    validation_checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "        monitor=\"validation\", filename=\"best\")\n",
    "    last_checkpoint = pl.callbacks.ModelCheckpoint(filename=\"last\")\n",
    "    val_check = {}\n",
    "    if len(train) >= VAL_EVERY:\n",
    "        val_check[\"val_check_interval\"] = VAL_EVERY\n",
    "    else:\n",
    "        nepoch = VAL_EVERY // len(train)\n",
    "        val_check[\"check_val_every_n_epoch\"] = nepoch\n",
    "    gin_hash = hashlib.md5(\n",
    "        gin.operative_config_str().encode()).hexdigest()[:10]\n",
    "    RUN_NAME = f'{NAME}_{gin_hash}'\n",
    "    os.makedirs(os.path.join(\"runs\", RUN_NAME), exist_ok=True)\n",
    "    if GPU == [-1]:\n",
    "        gpu = 0\n",
    "    else:\n",
    "        gpu = GPU or rave.core.setup_gpu()\n",
    "    print('selected gpu:', gpu)\n",
    "    accelerator = None\n",
    "    devices = None\n",
    "    if GPU == [-1]:\n",
    "        pass\n",
    "    elif torch.cuda.is_available():\n",
    "        accelerator = \"cuda\"\n",
    "        devices = GPU or rave.core.setup_gpu()\n",
    "    elif torch.backends.mps.is_available():\n",
    "        print(\n",
    "            \"Training on mac is not available yet. Use --gpu -1 to train on CPU (not recommended).\"\n",
    "        )\n",
    "        exit()\n",
    "        accelerator = \"mps\"\n",
    "        devices = 1\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        logger=pl.loggers.TensorBoardLogger(\n",
    "            \"runs\",\n",
    "            name=RUN_NAME,\n",
    "        ),\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        callbacks=[\n",
    "            validation_checkpoint,\n",
    "            last_checkpoint,\n",
    "            rave.model.WarmupCallback(),\n",
    "            rave.model.QuantizeCallback(),\n",
    "            rave.core.LoggerCallback(rave.core.ProgressLogger(RUN_NAME)),\n",
    "        ],\n",
    "        max_epochs=100000,\n",
    "        max_steps=MAX_STEPS,\n",
    "        profiler=\"simple\",\n",
    "        enable_progress_bar=PROGRESS,\n",
    "        **val_check,\n",
    "    )\n",
    "    run = rave.core.search_for_run(ckpt)\n",
    "    if run is not None:\n",
    "        step = torch.load(run, map_location='cpu')[\"global_step\"]\n",
    "        trainer.fit_loop.epoch_loop._batches_that_stepped = step\n",
    "\n",
    "    with open(os.path.join(\"runs\", RUN_NAME, \"config.gin\"), \"w\") as config_out:\n",
    "        config_out.write(gin.operative_config_str())\n",
    "\n",
    "    return trainer, model, train, val, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1305b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Path not found: v2.gin\n",
      "ERROR:root:Path not found: /home/ubuntu/RAVE/rave/v2.gin\n",
      "ERROR:root:Path not found: configs/v1.gin\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 3436 examples\n",
      "val set: 71 examples\n",
      "selected gpu: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer, model, train, val, run = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb876ce8-9453-408b-9dd1-d323a6115210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.11/lib/python3.10/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  warnings.warn(\n",
      "You are using a CUDA device ('NVIDIA A10') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type                  | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | pqmf                     | CachedPQMF            | 16.7 K\n",
      "1 | encoder                  | VariationalEncoder    | 16.1 M\n",
      "2 | decoder                  | GeneratorV2           | 15.5 M\n",
      "3 | discriminator            | CombineDiscriminators | 27.1 M\n",
      "4 | audio_distance           | AudioDistanceV1       | 0     \n",
      "5 | multiband_audio_distance | AudioDistanceV1       | 0     \n",
      "-------------------------------------------------------------------\n",
      "58.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "58.7 M    Total params\n",
      "234.734   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04386df0cfa04efea3f1ab5214521705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing receptive field for this configuration...\n",
      "Compression ratio: 2048x (~21.5Hz @ 44100Hz)\n",
      "Receptive field: 614.88ms <-- x --> 599.27ms\n",
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c400a28732754c29baacee1350e148d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.10.11/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('scale_multiband_spectral_distance', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.10.11/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('scale_fullband_spectral_distance', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "start_timer()\n",
    "trainer.fit(model, train, val, ckpt_path=run)\n",
    "end_timer_and_print(\"Default precision:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c569-be04-4413-8f4b-8489471842a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Saving/Resuming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05804fb0-298c-4f1e-a099-1aec555605ed",
   "metadata": {},
   "source": [
    "To save/resume Amp-enabled runs with bitwise accuracy, use\n",
    "[scaler.state_dict](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler.state_dict) and\n",
    "[scaler.load_state_dict](https://pytorch.org/docs/stable/amp.html#torch.cuda.amp.GradScaler.load_state_dict).\n",
    "\n",
    "When saving, save the ``scaler`` state dict alongside the usual model and optimizer state ``dicts``.\n",
    "Do this either at the beginning of an iteration before any forward passes, or at the end of\n",
    "an iteration after ``scaler.update()``.\n",
    "\n",
    "```\n",
    "checkpoint = {\"model\": net.state_dict(),\n",
    "              \"optimizer\": opt.state_dict(),\n",
    "              \"scaler\": scaler.state_dict()}\n",
    "```\n",
    "\n",
    "Write checkpoint as desired, e.g.,\n",
    "\n",
    "```\n",
    "torch.save(checkpoint, \"filename\")\n",
    "```\n",
    "\n",
    "When resuming, load the ``scaler`` state dict alongside the model and optimizer state ``dicts``.\n",
    "Read checkpoint as desired, for example:\n",
    "\n",
    "```\n",
    "dev = torch.cuda.current_device()\n",
    "checkpoint = torch.load(\"filename\",\n",
    "                        map_location = lambda storage, loc: storage.cuda(dev))\n",
    "```\n",
    "\n",
    "If a checkpoint was created from a run *without* Amp, and you want to resume training *with* Amp,\n",
    "load model and optimizer states from the checkpoint as usual.  The checkpoint won't contain a saved ``scaler`` state, so\n",
    "use a fresh instance of ``GradScaler``.\n",
    "\n",
    "If a checkpoint was created from a run *with* Amp and you want to resume training *without* ``Amp``,\n",
    "load model and optimizer states from the checkpoint as usual, and ignore the saved ``scaler`` state.\n",
    "\n",
    "\n",
    "```\n",
    "net.load_state_dict(checkpoint[\"model\"])\n",
    "opt.load_state_dict(checkpoint[\"optimizer\"])\n",
    "scaler.load_state_dict(checkpoint[\"scaler\"])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rave_env",
   "language": "python",
   "name": "rave_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
